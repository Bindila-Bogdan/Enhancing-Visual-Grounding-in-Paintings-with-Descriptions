{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa308455",
   "metadata": {},
   "source": [
    "# Embedding space visualization\n",
    "This notebook tests t-SNE and UMAP algorithms to plot the embeddings and understand if clusters are formed depending on features such as type, style or century of the painting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a77ce3",
   "metadata": {},
   "source": [
    "### 0. Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54925823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "INPUT_PATH_EMBEDDINGS = \"../../data/embeddings/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ae5424",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_embeddings = (\n",
    "    pl.read_json(\n",
    "        f\"{INPUT_PATH_EMBEDDINGS}baseline_embeddings_test_projections_text_embedding_enhanced_features.json\",\n",
    "        infer_schema_length=1000,\n",
    "    ).sort(\"painting_id\")\n",
    "    .with_row_index()\n",
    "    .with_columns((f\"test/\" + pl.col(\"index\").cast(pl.String) + \".png\").alias(\"image_name\"))\n",
    "    .with_columns((pl.col(\"year\") // 100 + 1).alias(\"century\"))\n",
    ")\n",
    "probabilities = projected_embeddings[\"probability\"]\n",
    "projected_embeddings = projected_embeddings.sort(\"probability\", descending=True).unique(subset=[\"object_description\"], keep=\"first\").sort(\"index\").drop(\"index\").with_row_index()\n",
    "\n",
    "\n",
    "clip_embeddings = (\n",
    "    pl.read_json(\n",
    "        f\"{INPUT_PATH_EMBEDDINGS}clip_embeddings_test_clip_full_1e_6_diff_lr_not_frozen_features.json\",\n",
    "        infer_schema_length=1000,\n",
    "    )\n",
    "    .with_columns((f\"test/\" + pl.col(\"index\").cast(pl.String) + \".png\").alias(\"image_name\"))\n",
    "    .with_columns((pl.col(\"year\") // 100 + 1).alias(\"century\"))\n",
    ").with_columns(pl.Series(probabilities).alias(\"probability\"))\n",
    "clip_embeddings = clip_embeddings.sort(\"probability\", descending=True).unique(subset=[\"object_description\"], keep=\"first\").sort(\"index\").drop(\"index\").with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip_embeddings = pl.read_json(\n",
    "#     f\"{INPUT_PATH_EMBEDDINGS}clip_embeddings_test_clip_full_1e_6_diff_lr_not_frozen_features.json\",\n",
    "#     infer_schema_length=2000,\n",
    "# ).with_columns((pl.col(\"year\") // 100 + 1).alias(\"century\"))\n",
    "\n",
    "# projected_embeddings = pl.read_json(\n",
    "#     f\"{INPUT_PATH_EMBEDDINGS}baseline_embeddings_test_projections_text_embedding_enhanced_features.json\",\n",
    "#     infer_schema_length=2000,\n",
    "# ).with_columns((pl.col(\"year\") // 100 + 1).alias(\"century\")).with_row_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(\n",
    "    complete_input_embeddings,\n",
    "    modality,\n",
    "    feature_name,\n",
    "    viz_algorithm=\"t-SNE\",\n",
    "    viz_algorithm_param=30,\n",
    "    top_feature_values=10,\n",
    "):\n",
    "    feature_values = (\n",
    "        complete_input_embeddings.filter(pl.col(feature_name).is_not_null())[feature_name]\n",
    "        .value_counts()\n",
    "        .sort(\"count\", descending=True)[:top_feature_values][feature_name]\n",
    "        .to_list()\n",
    "    )\n",
    "    input_embeddings = complete_input_embeddings.filter(pl.col(feature_name).is_in(feature_values))\n",
    "\n",
    "    print(\n",
    "        f\"Original size {complete_input_embeddings.shape[0]} - filtered size {input_embeddings.shape[0]}\"\n",
    "    )\n",
    "\n",
    "    if modality == \"visual\":\n",
    "        embeddings = np.stack(input_embeddings[\"embedding_object_image\"].to_numpy())\n",
    "    elif modality == \"textual\":\n",
    "        embeddings = np.stack(input_embeddings[\"text_embedding_enhanced\"].to_numpy())\n",
    "\n",
    "    if viz_algorithm == \"t-SNE\":\n",
    "        tsne = TSNE(\n",
    "            n_components=2, perplexity=viz_algorithm_param, random_state=42, metric=\"cosine\", method=\"exact\"\n",
    "        )\n",
    "        embeddings_2d = tsne.fit_transform(embeddings)\n",
    "    elif viz_algorithm == \"UMAP\":\n",
    "        umap = UMAP(\n",
    "            n_neighbors=viz_algorithm_param,\n",
    "            min_dist=0.9,\n",
    "            n_components=2,\n",
    "            random_state=42,\n",
    "            n_jobs=1,\n",
    "            metric=\"cosine\",\n",
    "        )\n",
    "        embeddings_2d = umap.fit_transform(embeddings)\n",
    "\n",
    "    embeddings_2d = pl.DataFrame(embeddings_2d).with_columns(\n",
    "        pl.Series(input_embeddings[feature_name]).cast(pl.String).alias(feature_name)\n",
    "    ).with_columns(\n",
    "        pl.Series(input_embeddings[\"object_description\"]).cast(pl.String).alias(\"object_description\")\n",
    "    ).with_columns(\n",
    "        pl.Series(input_embeddings[\"label\"]).cast(pl.String).alias(\"label\")\n",
    "    )\n",
    "\n",
    "    fig = px.scatter(\n",
    "        embeddings_2d.sort(feature_name),\n",
    "        x=\"column_0\",\n",
    "        y=\"column_1\",\n",
    "        color=feature_name,\n",
    "        symbol=feature_name,\n",
    "        hover_data=[feature_name, \"object_description\", \"label\"],\n",
    "        title=f\"{viz_algorithm} Visualization of Embeddings by Painting {feature_name.capitalize()}\",\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad2dfb",
   "metadata": {},
   "source": [
    "- 2 types of embeddings\n",
    "- 2 modalities\n",
    "- type, style, century, object\n",
    "---\n",
    "- label: perplexity 10\n",
    "- type: perplexity 10, 30\n",
    "---\n",
    "- Text modality\n",
    "    - coarse type - no well-defined clusters, but CLIP tends to have denser regions with points of the same painting type (906 points)\n",
    "    - style - the same, but the denser regions with the same attribute are not as  clearly visible as for type (411 points)\n",
    "    - century - no clusters are distinguishable, the same as before (1163 points)\n",
    "    - label - ?\n",
    "\n",
    "- Visual modality\n",
    "    - coarse type - no well-defined clusters, but CLIP tends to have denser regions with points of the same painting type\n",
    "    - style - as in the case of style for textual modality\n",
    "    - century - no clusters are distinguishable, the same as before\n",
    "    - label - ?\n",
    "\n",
    "In the case of visual modality, it's ok to have multiple images corresponding to the same descriptions\n",
    "In the case of textual modality, there will be clusters of with points with the same description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(clip_embeddings.clone(), \"visual\", \"label\", \"t-SNE\", 10)\n",
    "plot_embeddings(projected_embeddings.clone(), \"visual\", \"label\", \"t-SNE\", 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhance_vg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
