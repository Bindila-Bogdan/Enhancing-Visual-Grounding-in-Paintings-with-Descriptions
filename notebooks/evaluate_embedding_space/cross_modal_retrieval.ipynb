{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a08f95b2",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# Cross modal retrieval\n",
    "This notebook is used to evaluate the quality of the embedding space through cross-modal retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3927a7",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 0. Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93653974",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "DETAILED_EMBEDDING_SPACE_EVALUATION = True\n",
    "\n",
    "if DETAILED_EMBEDDING_SPACE_EVALUATION:\n",
    "    INPUT_PATH_EMBEDDINGS = \"../../../Open-Grounding-DINO/embeddings_data/\"\n",
    "    EMBEDDINGS_FILE_NAME = \"clip_embeddings_test_clip_full_2e_6_diff_lr.json\"\n",
    "    IMAGES_PATH = \"../../../Enhancing-Visual-Grounding-in-Paintings-with-Descriptions/data/fine-tuning_clip/\"\n",
    "\n",
    "else:\n",
    "    INPUT_PATH_EMBEDDINGS = \"../../data/embeddings/\"\n",
    "    EMBEDDINGS_FILE_NAME = \"baseline_embeddings_test_projections_text_embedding_enhanced_features.json\"\n",
    "    IMAGES_PATH = \"../../data/fine-tuning_clip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51134a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    embeddings_data = pl.read_json(f\"{INPUT_PATH_EMBEDDINGS}{EMBEDDINGS_FILE_NAME}\", infer_schema_length=1000).explode(pl.all())\n",
    "except:\n",
    "    embeddings_data = pl.read_json(f\"{INPUT_PATH_EMBEDDINGS}{EMBEDDINGS_FILE_NAME}\", infer_schema_length=1000)\n",
    "\n",
    "try:\n",
    "    embeddings_data = embeddings_data.with_row_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "indices = embeddings_data[\"index\"].to_list()\n",
    "embeddings_data = embeddings_data.with_columns((f\"test/\" + pl.col(\"index\").cast(pl.String) + \".png\").alias(\"image_name\")).rename({\"object_description\": \"text\"})\n",
    "embeddings_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46f2bb1",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 1. Define functions to perform retrieval and measure metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac53d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_documents(embeddings_data, description_embeddings, image_object_embeddings, query_index, query_type):\n",
    "    if query_type == \"description\":\n",
    "        # get object image embeddings based on description embedding\n",
    "        description_query = embeddings_data[\"text\"][query_index]\n",
    "        relevant_document_ids = embeddings_data.filter(pl.col(\"text\") == description_query)[\"index\"].to_numpy()\n",
    "\n",
    "        similarities = cosine_similarity(np.array(description_embeddings[query_index]).reshape(1, -1), np.array(image_object_embeddings))[0]\n",
    "        ranked_document_indices = np.argsort(similarities)[::-1]\n",
    "        sorted_similarities = np.sort(similarities)[::-1]\n",
    "\n",
    "    elif query_type == \"image\":\n",
    "        # get description embedding based on image object embedding\n",
    "        corresponding_descriptions = embeddings_data[\"text\"][query_index]\n",
    "        relevant_document_ids = embeddings_data.filter(pl.col(\"text\") == corresponding_descriptions)[\"index\"].to_numpy()\n",
    "\n",
    "        similarities = cosine_similarity(np.array(image_object_embeddings[query_index]).reshape(1, -1), np.array(description_embeddings))[0]\n",
    "        ranked_document_indices = np.argsort(similarities)[::-1]\n",
    "        sorted_similarities = np.sort(similarities)[::-1]\n",
    "\n",
    "    else:\n",
    "        raise NameError(\"This query type does not exist.\")\n",
    "        \n",
    "    return relevant_document_ids, ranked_document_indices, sorted_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1e2cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_retrieval(embeddings_data, description_embeddings, image_object_embeddings, indices, query_type):\n",
    "    hit_at_1 = []\n",
    "    hit_at_5 = []\n",
    "    hit_at_10 = []\n",
    "    first_rank = []\n",
    "    reciprocal_first_rank = []\n",
    "\n",
    "    for query_index in tqdm(indices):\n",
    "        relevant_document_ids, ranked_document_indices, sorted_similarities = retrieve_documents(embeddings_data, description_embeddings, image_object_embeddings, query_index, query_type)\n",
    "\n",
    "        hit_at_1.append(int(np.isin(relevant_document_ids, ranked_document_indices[:1]).any()))\n",
    "        hit_at_5.append(int(np.isin(relevant_document_ids, ranked_document_indices[:5]).any()))\n",
    "        hit_at_10.append(int(np.isin(relevant_document_ids, ranked_document_indices[:10]).any()))\n",
    "\n",
    "        first_rank.append(np.where(np.isin(ranked_document_indices, relevant_document_ids) == True)[0][0] + 1)\n",
    "        reciprocal_first_rank.append(1 / first_rank[-1])\n",
    "\n",
    "    hit_rate_at_1 = np.array(hit_at_1).mean()\n",
    "    hit_rate_at_5 = np.array(hit_at_5).mean()\n",
    "    hit_rate_at_10 = np.array(hit_at_10).mean()\n",
    "    median_rank = round(np.median(np.array(first_rank)), 2)\n",
    "    mean_reciprocal_rank = round(np.array(reciprocal_first_rank).mean(), 4)\n",
    "\n",
    "    print(f\"Hit@1: {hit_rate_at_1}\\nHit@5: {hit_rate_at_5}\\nHit@10: {hit_rate_at_10}\\nMedian Rank: {median_rank}\\nMRR: {mean_reciprocal_rank}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8bdc5f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 2. Perform retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf0d3e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_object_embeddings = embeddings_data[\"embedding_object_image\"].to_list()\n",
    "\n",
    "try:\n",
    "    description_embeddings_enhanced = embeddings_data[\"text_embedding_enhanced\"].to_list()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    description_embeddings_backbone = embeddings_data[\"text_embedding_backbone\"].to_list()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90186f9b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### 2.1. Use image objects as queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da1001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    evaluate_retrieval(embeddings_data, description_embeddings_backbone, image_object_embeddings, indices, \"image\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0bec1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    evaluate_retrieval(embeddings_data, description_embeddings_enhanced, image_object_embeddings, indices, \"image\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c4d52",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### 2.2. Use descriptions as queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d4189",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    evaluate_retrieval(embeddings_data, description_embeddings_backbone, image_object_embeddings, indices, \"description\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352f172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    evaluate_retrieval(embeddings_data, description_embeddings_enhanced, image_object_embeddings, indices, \"description\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537a897",
   "metadata": {},
   "source": [
    "### 3. Perform retrieval based on type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ebb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_data[\"coarse_type\"].value_counts().sort(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_types = set(embeddings_data.filter(pl.col(\"coarse_type\").is_not_null())[\"coarse_type\"].to_list())\n",
    "coarse_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c79158",
   "metadata": {},
   "source": [
    "#### 3.1. Use image objects as queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66dfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coarse_type in coarse_types:\n",
    "    print(f\"{\"-\" * len(coarse_type)}\\n{coarse_type}\")\n",
    "    indices_current_type = embeddings_data.filter(pl.col(\"coarse_type\") == coarse_type)[\"index\"].to_list()\n",
    "    evaluate_retrieval(embeddings_data, description_embeddings_enhanced, image_object_embeddings, indices_current_type, \"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8699a01",
   "metadata": {},
   "source": [
    "#### 3.2. Use descriptions as queries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c36c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for coarse_type in coarse_types:\n",
    "    print(f\"{\"-\" * len(coarse_type)}\\n{coarse_type}\")\n",
    "    indices_current_type = embeddings_data.filter(pl.col(\"coarse_type\") == coarse_type)[\"index\"].to_list()\n",
    "    evaluate_retrieval(embeddings_data, description_embeddings_enhanced, image_object_embeddings, indices_current_type, \"description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8314111-97bb-4336-83d7-22721a9d98be",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### 4. Perform visual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f7b32-f6d2-48b8-8a3e-4fa4b6d07aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_images_in_row_plotly(image_list, titles=None):\n",
    "    \"\"\"\n",
    "    Displays a list of PIL images in a row using Plotly subplots.\n",
    "\n",
    "    Args:\n",
    "        image_list (list): A list of PIL Image objects.\n",
    "        titles (list, optional): A list of titles for each image.\n",
    "                                 Must be the same length as image_list.\n",
    "    \"\"\"\n",
    "    if not image_list:\n",
    "        print(\"The image list is empty.\")\n",
    "        return\n",
    "\n",
    "    num_images = len(image_list)\n",
    "\n",
    "    if titles and len(titles) != num_images:\n",
    "        print(\"Warning: Number of titles does not match number of images. Titles will be ignored.\")\n",
    "        titles = None\n",
    "\n",
    "    # Create subplots: 1 row, num_images columns\n",
    "    fig = make_subplots(rows=1, cols=num_images, subplot_titles=titles)\n",
    "\n",
    "    for i, pil_img in enumerate(image_list):\n",
    "        # Convert PIL image to NumPy array\n",
    "        np_img = np.array(pil_img)\n",
    "\n",
    "        # Add image trace to the subplot\n",
    "        fig.add_trace(\n",
    "            go.Image(z=np_img),\n",
    "            row=1, col=i + 1  # i+1 because columns are 1-indexed\n",
    "        )\n",
    "\n",
    "        # Remove axis labels and ticks for cleaner image display\n",
    "        fig.update_xaxes(showticklabels=False, showgrid=False, zeroline=False, row=1, col=i + 1)\n",
    "        fig.update_yaxes(showticklabels=False, showgrid=False, zeroline=False, row=1, col=i + 1)\n",
    "\n",
    "    # Update layout for better appearance\n",
    "    fig.update_layout(\n",
    "        title_text=\"PIL Images in a Row (Plotly)\",\n",
    "        # Adjust height as needed. Width will scale with number of images.\n",
    "        height=300, \n",
    "        # Optionally set a fixed width if you want, but autosize usually works well.\n",
    "        # width=num_images * 200, \n",
    "        margin=dict(l=20, r=20, t=50, b=20) # Adjust margins\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2fd90-0d82-4438-ae6c-892b10601f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # for more diverse results, keep only the most probable bounding box per description\n",
    "# embeddings_data = (\n",
    "#     embeddings_data.sort(\"probability\", descending=True)\n",
    "#     .group_by(\"text\", maintain_order=True)\n",
    "#     .agg(pl.all().first())\n",
    "#     .sort(\"painting_id\")\n",
    "# )\n",
    "# image_object_embeddings = embeddings_data[\"embedding_object_image\"].to_list()\n",
    "\n",
    "# try:\n",
    "#     description_embeddings_enhanced = embeddings_data[\"text_embedding_enhanced\"].to_list()\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# try:\n",
    "#     description_embeddings_backbone = embeddings_data[\"text_embedding_backbone\"].to_list()\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8976cc-c2bd-4cf8-a94e-ae625487c46d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_index = 188\n",
    "relevant_document_ids, ranked_document_indices, sorted_similarities = retrieve_documents(embeddings_data, description_embeddings_enhanced, image_object_embeddings, query_index=query_index, query_type=\"image\")\n",
    "\n",
    "relevant_images = [Image.open(f\"{IMAGES_PATH}{embeddings_data['image_name'][int(index)]}\") for index in relevant_document_ids[:5]] \n",
    "relevant_descriptions = set([embeddings_data['text'][int(index)] for index in relevant_document_ids[:5]])\n",
    "\n",
    "retrieved_images = [Image.open(f\"{IMAGES_PATH}{embeddings_data['image_name'][int(index)]}\") for index in ranked_document_indices[:5]]\n",
    "retrieved_descriptions = [embeddings_data['text'][int(index)] for index in ranked_document_indices[:5]]\n",
    "\n",
    "print(\"==QUERY==\")\n",
    "for description in relevant_descriptions:\n",
    "    print(description)\n",
    "display_images_in_row_plotly(relevant_images)\n",
    "\n",
    "print(\"==RETRIEVED==\")\n",
    "for description in retrieved_descriptions:\n",
    "    print(description)\n",
    "display_images_in_row_plotly(retrieved_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff3de3-a34e-4e5e-84d4-d5027d783e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_index = 188\n",
    "relevant_document_ids, ranked_document_indices, sorted_similarities = retrieve_documents(embeddings_data, description_embeddings_enhanced, image_object_embeddings, query_index=query_index, query_type=\"description\")\n",
    "\n",
    "relevant_images = [Image.open(f\"{IMAGES_PATH}{embeddings_data['image_name'][int(index)]}\") for index in relevant_document_ids[:5]] \n",
    "relevant_descriptions = set([embeddings_data['text'][int(index)] for index in relevant_document_ids[:5]])\n",
    "\n",
    "retrieved_images = [Image.open(f\"{IMAGES_PATH}{embeddings_data['image_name'][int(index)]}\") for index in ranked_document_indices[:5]]\n",
    "retrieved_descriptions = [embeddings_data['text'][int(index)] for index in ranked_document_indices[:5]]\n",
    "\n",
    "print(\"==QUERY==\")\n",
    "for description in relevant_descriptions:\n",
    "    print(description)\n",
    "display_images_in_row_plotly(relevant_images)\n",
    "\n",
    "print(\"==RETRIEVED==\")\n",
    "for description in retrieved_descriptions:\n",
    "    print(description)\n",
    "display_images_in_row_plotly(retrieved_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhance_vg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
