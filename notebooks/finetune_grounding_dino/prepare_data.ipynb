{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3c177f",
   "metadata": {},
   "source": [
    "# Prepare data for fine-tuning\n",
    "Prepare data for fine-tuning the Open Grounding DINO model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc8f98",
   "metadata": {},
   "source": [
    "### 0. Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84b038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import shutil\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RAW_DATA_PATH = \"../../data/raw/\"\n",
    "PROCESSED_DATA_PATH = \"../../data/processed/\"\n",
    "\n",
    "TEXT_INCLUDED = \"labels\"\n",
    "STORAGE_PATH = \"../../data/fine-tuning/\"\n",
    "\n",
    "# TEXT_INCLUDED = \"descriptions\"\n",
    "# STORAGE_PATH = \"../../data/baseline/\"\n",
    "\n",
    "sys.path.append(\"../annotate_dataset/\")\n",
    "\n",
    "from annotate_paintings_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a136ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PROCESSED_DATA_PATH}paintings_with_filtered_objects.json\") as f:\n",
    "    all_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8c5a7",
   "metadata": {},
   "source": [
    "### 1. Create the stratified train/validation/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paintings_data = pl.from_dicts(\n",
    "    [\n",
    "        {key: value for key, value in annotation.items() if key != \"objects\"}\n",
    "        for annotation in all_annotations\n",
    "    ]\n",
    ")\n",
    "paintings_data = paintings_data.with_columns((pl.col(\"year\") // 100).alias(\"century\"))\n",
    "stratify_cols = [\"century\", \"source\", \"coarse_type\", \"first_style\"]\n",
    "\n",
    "paintings_data = paintings_data.with_columns(\n",
    "    pl.col(col).cast(pl.Utf8).fill_null(\"\") for col in stratify_cols\n",
    ").with_columns(\n",
    "    pl.struct(stratify_cols)\n",
    "    .map_elements(lambda x: \"_\".join(str(v) for v in x.values()), return_dtype=pl.String)\n",
    "    .alias(\"stratify_key\")\n",
    ")\n",
    "\n",
    "rare_stratify_keys = (\n",
    "    paintings_data[\"stratify_key\"]\n",
    "    .value_counts()\n",
    "    .filter(pl.col(\"count\") < 10)[\"stratify_key\"]\n",
    "    .to_list()\n",
    ")\n",
    "paintings_data = paintings_data.with_columns(\n",
    "    pl.when(pl.col(\"stratify_key\").is_in(rare_stratify_keys))\n",
    "    .then(pl.lit(\"other\"))\n",
    "    .otherwise(pl.col(\"stratify_key\"))\n",
    "    .alias(\"updated_statify_key\")\n",
    ")\n",
    "\n",
    "painting_ids = paintings_data[\"id\"].to_numpy()\n",
    "stratify_key = paintings_data[\"updated_statify_key\"].to_numpy()\n",
    "\n",
    "train_ids, temp_ids, _, temp_stratify_key = train_test_split(\n",
    "    painting_ids, stratify_key, test_size=0.20, random_state=42, stratify=stratify_key\n",
    ")\n",
    "\n",
    "val_ids, test_ids, _, _ = train_test_split(\n",
    "    temp_ids, temp_stratify_key, test_size=0.50, random_state=42, stratify=temp_stratify_key\n",
    ")\n",
    "print(f\"Train: {len(train_ids)} Validation: {len(val_ids)} Test: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcdbc52",
   "metadata": {},
   "source": [
    "### 1. Create data for fine-tuning in jsonl format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa39ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(STORAGE_PATH)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(STORAGE_PATH + \"train/\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.mkdir(STORAGE_PATH + \"train/\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(STORAGE_PATH + \"val/\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.mkdir(STORAGE_PATH + \"val/\")\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(STORAGE_PATH + \"test/\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "os.mkdir(STORAGE_PATH + \"test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(all_annotations, set_name, tokenizer):\n",
    "    annotations = []\n",
    "    too_long_desc_counter = 0\n",
    "    paintings_with_long_descriptions = []\n",
    "\n",
    "    for painting_annotations in tqdm(all_annotations):\n",
    "        painting_id = painting_annotations[\"id\"]\n",
    "        extracted_obj_desc = [[obj.replace(\".\", \"\"), re.sub(r' +', ' ', obj_data[\"description\"][:-1].replace(\".\", \" | \").strip())] for obj, obj_data in painting_annotations[\"objects\"].items()]\n",
    "\n",
    "        if TEXT_INCLUDED == \"labels\":\n",
    "            caption = \" . \".join([obj_info[0] for obj_info in extracted_obj_desc]) + \" .\"\n",
    "        elif TEXT_INCLUDED == \"descriptions\":\n",
    "            caption = \" . \".join([obj_info[1] for obj_info in extracted_obj_desc]) + \" .\"\n",
    "\n",
    "        if len(tokenizer.tokenize(caption)) > 254:\n",
    "            too_long_desc_counter += 1\n",
    "            paintings_with_long_descriptions.append(painting_id)\n",
    "            continue\n",
    "\n",
    "        image = load_image(painting_id)[1]\n",
    "\n",
    "        current_annotation = {\n",
    "            \"filename\": f\"{painting_id}.png\",\n",
    "            \"height\": image.size[1],\n",
    "            \"width\": image.size[0],\n",
    "        }\n",
    "        regions = []\n",
    "\n",
    "        for obj, desc in extracted_obj_desc:\n",
    "            for bbox in painting_annotations[\"objects\"][obj][\"bounding_boxes\"]:\n",
    "                if TEXT_INCLUDED == \"labels\":\n",
    "                    regions.append({\"bbox\": bbox[1], \"phrase\": obj})\n",
    "                elif TEXT_INCLUDED == \"descriptions\":\n",
    "                    regions.append({\"bbox\": bbox[1], \"phrase\": desc})\n",
    "\n",
    "        current_annotation[\"grounding\"] = {\n",
    "            \"caption\": caption,\n",
    "            \"regions\": regions,\n",
    "        }\n",
    "\n",
    "        annotations.append(current_annotation)\n",
    "        source_path = f\"{RAW_DATA_PATH}filtered_paintings/{painting_id}.png\"\n",
    "        destination_path = f\"{STORAGE_PATH}{set_name}/{painting_id}.png\"\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "\n",
    "    with open(f\"{STORAGE_PATH}{set_name}/{set_name}_annotations.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in annotations:\n",
    "            json_line = json.dumps(item, ensure_ascii=False)\n",
    "            f.write(json_line + \"\\n\")\n",
    "\n",
    "    print(f\"{too_long_desc_counter} paintings from the {set_name} set have to long cumulated object descriptions.\")\n",
    "    print(paintings_with_long_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a1bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_annotations = [annotation for annotation in all_annotations if annotation[\"id\"] in train_ids]\n",
    "create_dataset(train_annotations, \"train\", tokenizer)\n",
    "val_annotations = [annotation for annotation in all_annotations if annotation[\"id\"] in val_ids]\n",
    "create_dataset(val_annotations, \"val\", tokenizer)\n",
    "test_annotations = [annotation for annotation in all_annotations if annotation[\"id\"] in test_ids]\n",
    "create_dataset(test_annotations, \"test\", tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd27cd",
   "metadata": {},
   "source": [
    "### 2. Analyze object labels per each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb73e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_set = test_annotations\n",
    "\n",
    "object_labels = []\n",
    "object_descriptions = []\n",
    "\n",
    "for annotation in chosen_set:\n",
    "    object_labels.append(list(annotation[\"objects\"].keys()))\n",
    "    object_descriptions.append([obj_data[\"description\"] for obj_data in annotation[\"objects\"].values()])\n",
    "    \n",
    "paintings_objects = copy.deepcopy(chosen_set)\n",
    "\n",
    "for index, painting_objects in enumerate(paintings_objects):\n",
    "    paintings_objects[index][\"objects\"] = object_labels[index]\n",
    "    paintings_objects[index][\"object_description\"] = object_descriptions[index]\n",
    "\n",
    "paintings_objects = pl.from_dicts(paintings_objects, infer_schema_length=1000).explode(\"objects\", \"object_description\")\n",
    "print(f\"Number of objects: {paintings_objects.shape[0]}\")\n",
    "\n",
    "unique_labels = paintings_objects.group_by(\"objects\").len().sort(\"len\", descending=True)\n",
    "print(f\"The number of unique labels: {unique_labels.shape[0]}\")\n",
    "\n",
    "with pl.Config(tbl_rows=100):\n",
    "    display(unique_labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d076e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhance_vg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
